{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Intro to Machine Learning - Identify Fraud from Enron Email - Nitin Ramchand Lalwani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what POI is and the enron scandal overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def open_dataset():\n",
    "    with open(\"C:\\Users\\RAMCHAND_N\\Data Analytics Nanodegree\\CORE_Module4_IntrotoMachineLearning\\CORE_Module4_Intro_to_Machine_Learning_NitinRamchandLalwani\\Lesson 2- Naive Bayes\\\\ud120-projects-master\\\\ud120-projects-master\\\\final_project\\\\final_project_dataset.pkl\", \"r\") as data_file:\n",
    "        data_dict = pickle.load(data_file)\n",
    "    return data_dict\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "\n",
    "\n",
    "my_dataset = open_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following structure when loaded. It is a python dictionary with people's names as keys and another dictionary as values. In this dictionary, there are all the following features which will be used for the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 600000,\n",
      " 'deferral_payments': 'NaN',\n",
      " 'deferred_income': 'NaN',\n",
      " 'director_fees': 'NaN',\n",
      " 'email_address': 'mark.metts@enron.com',\n",
      " 'exercised_stock_options': 'NaN',\n",
      " 'expenses': 94299,\n",
      " 'from_messages': 29,\n",
      " 'from_poi_to_this_person': 38,\n",
      " 'from_this_person_to_poi': 1,\n",
      " 'loan_advances': 'NaN',\n",
      " 'long_term_incentive': 'NaN',\n",
      " 'other': 1740,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 585062,\n",
      " 'restricted_stock_deferred': 'NaN',\n",
      " 'salary': 365788,\n",
      " 'shared_receipt_with_poi': 702,\n",
      " 'to_messages': 807,\n",
      " 'total_payments': 1061827,\n",
      " 'total_stock_value': 585062}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(my_dataset['METTS MARK'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of people we have in the dataset are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below there are in total 18 names that have a Person of Interest (POI) tag which comes are the ones containing a True value in for the \"POI\" feature. This are the number of POIs we have in the dataset, and in total we have 146 people so it means that defining a classification algorithm, we must remember that it is not balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(poi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the POI_names.txt file however we have a total of 35 POIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\Users\\RAMCHAND_N\\Data Analytics Nanodegree\\CORE_Module4_IntrotoMachineLearning\\CORE_Module4_Intro_to_Machine_Learning_NitinRamchandLalwani\\Lesson 2- Naive Bayes\\\\ud120-projects-master\\\\ud120-projects-master\\\\final_project\\\\poi_names.txt\") as f:\n",
    "    print len(f.readlines()[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to understand which how much information we have for each of the features for each of the 146 people in our dataset. So some values inside the dataset are shown as \"NaN\" and we are looking for the percetages of information in the dataset that are not \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bonus': 0.5616,\n",
      " 'deferral_payments': 0.2671,\n",
      " 'deferred_income': 0.3356,\n",
      " 'director_fees': 0.1164,\n",
      " 'email_address': 0.7603,\n",
      " 'exercised_stock_options': 0.6986,\n",
      " 'expenses': 0.6507,\n",
      " 'from_messages': 0.589,\n",
      " 'from_poi_to_this_person': 0.589,\n",
      " 'from_this_person_to_poi': 0.589,\n",
      " 'loan_advances': 0.0274,\n",
      " 'long_term_incentive': 0.4521,\n",
      " 'other': 0.637,\n",
      " 'poi': 1.0,\n",
      " 'restricted_stock': 0.7534,\n",
      " 'restricted_stock_deferred': 0.1233,\n",
      " 'salary': 0.6507,\n",
      " 'shared_receipt_with_poi': 0.589,\n",
      " 'to_messages': 0.589,\n",
      " 'total_payments': 0.8562,\n",
      " 'total_stock_value': 0.863}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from pprint import pprint\n",
    "from __future__ import division\n",
    "populated_data_count = collections.defaultdict(int)\n",
    "populated_data_percentage = {}\n",
    "features = next(my_dataset.itervalues()).keys()\n",
    "for person_features in my_dataset.itervalues():\n",
    "    for feature in features:\n",
    "        if person_features[feature] != \"NaN\":\n",
    "            populated_data_count[feature] += 1\n",
    "for k,v in populated_data_count.iteritems():\n",
    "    populated_data_percentage[k] = round((v/len(my_dataset)),4)\n",
    "#pprint(populated_data_count)\n",
    "pprint(populated_data_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this first exploration, we see that there are some features that don't have much data so lets hihglight the ones that have less than 50% of the people filled which are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'deferral_payments'\n",
      "'restricted_stock_deferred'\n",
      "'deferred_income'\n",
      "'loan_advances'\n",
      "'long_term_incentive'\n",
      "'director_fees'\n"
     ]
    }
   ],
   "source": [
    "for k, v in populated_data_percentage.iteritems():\n",
    "    if v < 0.5:\n",
    "        pprint(k)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further step, we look at whether from these 6 features without a lot of infomration, whether any of them have information for a lot of POIs at the same time since this may be auseful hint to investigate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deferral_income_and_poi 11\n",
      "loan_advances_and_poi 1\n",
      "restricted_stock_deferred_and_poi 0\n",
      "deferral_payments_and_poi 5\n",
      "long_term_incentive_and_poi 12\n",
      "director_fees_and_poi 0\n"
     ]
    }
   ],
   "source": [
    "poi= []\n",
    "deferral_payments_and_poi = []\n",
    "restricted_stock_deferred_and_poi = []\n",
    "deferral_income_and_poi = []\n",
    "loan_advances_and_poi = []\n",
    "long_term_incentive_and_poi = []\n",
    "director_fees_and_poi = []\n",
    "for person in my_dataset:\n",
    "    restricted_stock_deferred_and_poi.append((my_dataset[person]['restricted_stock_deferred'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    poi.append(my_dataset[person]['poi'] == True)\n",
    "    deferral_payments_and_poi.append((my_dataset[person]['deferral_payments'] != \"NaN\") & (my_dataset[person]['poi'] == True) )\n",
    "    deferral_income_and_poi.append((my_dataset[person]['deferred_income'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    loan_advances_and_poi.append((my_dataset[person]['loan_advances'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    long_term_incentive_and_poi.append((my_dataset[person]['long_term_incentive'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    director_fees_and_poi.append((my_dataset[person]['director_fees'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "print \"deferral_income_and_poi\" , sum(deferral_income_and_poi)\n",
    "print \"loan_advances_and_poi\" ,sum(loan_advances_and_poi)\n",
    "print \"restricted_stock_deferred_and_poi\" ,sum(restricted_stock_deferred_and_poi)\n",
    "print \"deferral_payments_and_poi\" , sum(deferral_payments_and_poi)\n",
    "print \"long_term_incentive_and_poi\" ,sum(long_term_incentive_and_poi)\n",
    "print \"director_fees_and_poi\" ,sum(director_fees_and_poi)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for the deferral_income and long_term_incentive features there is not much information overall (for less than 50% of people in the dataset) but there is significantly high percentage of data for those people that have a __True__ tag in POI, so we can discard the other four features but we can keep these two just incase they provide us good information for the classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code just in case for future but not part of the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deferral_income_and_poi 11\n",
      "director_fees_and_poi 0\n",
      "email_address_and_poi 18\n",
      "exercised_stock_options_and_poi 12\n",
      "expenses_and_poi 18\n",
      "from_messages_and_poi 14\n",
      "from_poi_to_this_person_and_poi 14\n",
      "from_this_person_to_poi_and_poi 14\n",
      "loan_advances_and_poi 1\n",
      "long_term_incentive_and_poi 12\n",
      "other_and_poi 18\n",
      "restricted_stock_deferred_and_poi 0\n",
      "salary_and_poi 17\n",
      "shared_receipt_with_poi_and_poi 14\n",
      "to_messages_and_poi 14\n",
      "total_payments_and_poi 18\n",
      "total_stock_value_and_poi 18\n",
      "bonus_and_poi 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "email_address_and_poi = []\n",
    "exercised_stock_options_and_poi = []\n",
    "expenses_and_poi = []\n",
    "from_messages_and_poi = []\n",
    "from_poi_to_this_person_and_poi = []\n",
    "from_this_person_to_poi_and_poi = []\n",
    "other_and_poi = []\n",
    "salary_and_poi = []\n",
    "shared_receipt_with_poi_and_poi = []\n",
    "to_messages_and_poi = []\n",
    "total_payments_and_poi = []\n",
    "total_stock_value_and_poi = []\n",
    "bonus_and_poi = []\n",
    "for person in my_dataset:\n",
    "    email_address_and_poi.append((my_dataset[person]['email_address'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    exercised_stock_options_and_poi.append((my_dataset[person]['exercised_stock_options'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    expenses_and_poi.append((my_dataset[person]['expenses'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    from_messages_and_poi.append((my_dataset[person]['from_messages'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    from_poi_to_this_person_and_poi.append((my_dataset[person]['from_poi_to_this_person'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    from_this_person_to_poi_and_poi.append((my_dataset[person]['from_this_person_to_poi'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    other_and_poi.append((my_dataset[person]['other'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    salary_and_poi.append((my_dataset[person]['salary'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    shared_receipt_with_poi_and_poi.append((my_dataset[person]['shared_receipt_with_poi'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    to_messages_and_poi.append((my_dataset[person]['to_messages'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    total_payments_and_poi.append((my_dataset[person]['total_payments'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    total_stock_value_and_poi.append((my_dataset[person]['total_stock_value'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "    bonus_and_poi.append((my_dataset[person]['bonus'] != \"NaN\") & (my_dataset[person]['poi'] == True))\n",
    "print \"email_address_and_poi\" ,sum(email_address_and_poi)\n",
    "print \"exercised_stock_options_and_poi\" ,sum(exercised_stock_options_and_poi)\n",
    "print \"expenses_and_poi\" ,sum(expenses_and_poi)\n",
    "print \"from_messages_and_poi\" ,sum(from_messages_and_poi)\n",
    "print \"from_poi_to_this_person_and_poi\" ,sum(from_poi_to_this_person_and_poi)\n",
    "print \"from_this_person_to_poi_and_poi\" ,sum(from_this_person_to_poi_and_poi)\n",
    "print \"other_and_poi\" ,sum(other_and_poi)\n",
    "print \"salary_and_poi\" ,sum(salary_and_poi)\n",
    "print \"shared_receipt_with_poi_and_poi\" ,sum(shared_receipt_with_poi_and_poi)\n",
    "print \"to_messages_and_poi\" ,sum(to_messages_and_poi)\n",
    "print \"total_payments_and_poi\" ,sum(total_payments_and_poi)\n",
    "print \"total_stock_value_and_poi\" ,sum(total_stock_value_and_poi)\n",
    "print \"bonus_and_poi\" ,sum(bonus_and_poi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
